# Academic Software License: Copyright Â© 2025 Goodarz Mehr.

'''
Module that manages the calculations for obtaining the BEV ground truth, 3D
object bounding boxes, and HD map information.
'''

import cv2
import json
import carla
import logging

import numpy as np

from utils import *

from typing import List

from skimage.morphology import binary_closing, binary_opening

from scipy.spatial.distance import cdist


logger = logging.getLogger(__name__)


TRAFFIC_SIGN = {
    'highwaySign': 'highway',
    'pole_': 'billboard',
    'DoNoEnter': 'do_not_enter',
    'Interchange': 'interchange',
    'NoTrunLeft': 'no_left_turn',
    'busNoPark': 'bus_stop_no_parking',
    'cleanPet': 'clean_up_after_pet',
    'minPark': 'parking_time_limit',
    'noBicyc': 'no_bicycles',
    'noPark': 'no_parking',
    'noPed': 'no_pedestrians',
    'noStand': 'no_standing',
    'onlyCrossw': 'cross_only_at_crosswalk',
    'photo': 'photo_enforced',
    'reserved': 'reserved_parking',
    'school': 'school_zone',
    'stopPed': 'stop_for_pedestrians',
    'tow': 'tow_away_zone',
    'yieldPed': 'yield_to_pedestrians',
    'passenger': 'passenger_cars_only',
    'DiamondSignal': 'accident_ahead',
    'wildCrossing': 'animal_crossing',
    'AnimalCrossing': 'animal_crossing',
    'LaneReduceL': 'lane_reduction',
    'LaneReduct': 'lane_reduction',
    'MichiganLeft': 'michigan_left',
    'NoTurns': 'no_turns',
    'noTurn': 'no_turns',
    'OneWay': 'one_way',
    'oneWay': 'one_way',
    'stopSign': 'stop',
    'STOP_': 'stop',
    '_Stop': 'stop',
    '_Yield': 'yield',
    '_yield_': 'yield',
    '_Flag': 'street_name',
    '_letter': 'street_name',
    'SpeedLimiter': 'speed_limit',
    'SpeedSign': 'speed_limit',
    '_SpeedLimit': 'speed_limit',
    'SpeedLimit20': 'speed_limit_20',
    'SpeedLimit25': 'speed_limit_25',
    'SpeedLimit30': 'speed_limit_30',
    'SpeedLimit40': 'speed_limit_40',
    'SpeedLimit50': 'speed_limit_50',
    'SpeedLimit55': 'speed_limit_55',
    'SpeedLimit60': 'speed_limit_60',
    'SpeedLimit70': 'speed_limit_70',
    'SpeedLimit75': 'speed_limit_75',
    'SpeedLimit80': 'speed_limit_80',
    'SpeedLimit90': 'speed_limit_90',
    'SpeedLimit100': 'speed_limit_100',
    'SpeedLimit110': 'speed_limit_110',
    'SpeedLimit120': 'speed_limit_120',
    'SpeedLimit20_15': 'speed_limit_20_min_15',
    'SpeedLimit25_15': 'speed_limit_25_min_15',
    'SpeedLimit30_15': 'speed_limit_30_min_15',
    'SpeedLimit50_40': 'speed_limit_50_min_40',
    'SpeedLimit55_40': 'speed_limit_55_min_40',
    'SpeedLimit75_45': 'speed_limit_75_min_45',
}

BAD_CROSSWALKS = [
    'Road_Crosswalk_Town03_59_',
    'Road_Crosswalk_Town04_28_',
    'Road_Crosswalk_Town04_29_',
    'Road_Crosswalk_Town04_30_',
    'Road_Crosswalk_Town07_5_',
    'Road_Crosswalk_Town07_8_',
    'Road_Crosswalk_Town07_9_'
]

MAP_PALETTE = {
    'road': (196, 80, 196),
    'road_line': (160, 240, 40),
    'sidewalk': (240, 196, 240),
    'crosswalk': (240, 196, 196),
    'car': (0, 128, 240),
    'truck': (80, 240, 80),
    'bus': (0, 144, 0),
    'motorcycle': (240, 240, 0),
    'bicycle': (0, 240, 240),
    'rider': (240, 144, 0),
    'pedestrian': (240, 0, 0)
}

CITYSCAPE_PALETTE = {
    'road': (128, 64, 128),
    'road_line': (227, 227, 227),
    'sidewalk': (244, 35, 232),
    'crosswalk': (157, 234, 50),
    'car': (0, 0, 142),
    'truck': (0, 0, 70),
    'bus': (0, 60, 100),
    'motorcycle': (0, 0, 230),
    'bicycle': (119, 11, 32),
    'rider': (255, 0, 0),
    'pedestrian': (220, 20, 60)
}


class GTManager:
    '''
    The Ground Truth Manager manages the calculations for obtaining the BEV
    ground truth, 3D object bounding boxes, and HD map information.

    Args:
        config: dictionary of configuration parameters.
        world: CARLA world.
        vehicle: ego vehicle.
        sensor_manager: ego vehicle's sensor manager.
        map_name: name of the CARLA map.
    '''
    def __init__(self, config, world, vehicle, sensor_manager, map_name):
        self.config = config
        self.world = world
        self.vehicle = vehicle
        self.sensor_manager = sensor_manager
        self.map_name = map_name

        self.map = self.world.get_map()
        self.objects = self.world.get_environment_objects()

    def augment_waypoints(self, waypoints: List[carla.Waypoint]):
        '''
        Augment the list of waypoints generated by CARLA.
        
        Args:
            waypoints: list of waypoints.
        '''
        self.warning_flag = False

        # Filter the list of waypoints to get those near the spawn area.
        vehicle_location = self.vehicle.get_location()
        
        area_waypoints = [
            wp for wp in waypoints if vehicle_location.distance(
                wp.transform.location
            ) < self.config['mapping_area_radius']
        ]

        # The list of generated waypoints only includes those in lanes where
        # the lane type is Driving. Our goal is to add ones in the adjacent
        # lanes, if those lanes are Parking, Bidirectional, or Biking; or if
        # those lanes are NONE, Shoulder, or Border, provided that at least
        # one of the lane markings is not NONE, Grass, or Curb.
        self.good_lane_types = [carla.LaneType.Parking, carla.LaneType.Bidirectional, carla.LaneType.Biking]
        self.conditional_lane_types = [carla.LaneType.NONE, carla.LaneType.Shoulder, carla.LaneType.Border]

        self.bad_lane_marking_types = [
            carla.LaneMarkingType.NONE,
            carla.LaneMarkingType.Grass,
            carla.LaneMarkingType.Curb
        ]
        self.single_lane_marking_types = [
            carla.LaneMarkingType.Solid,
            carla.LaneMarkingType.Broken,
            carla.LaneMarkingType.Other,
            carla.LaneMarkingType.BottsDots
        ]

        logger.debug('Compiling a list of road waypoints...')

        adjacent_waypoints = []

        # Get the adjacent waypoints on both sides.
        for wp in area_waypoints:
            self._get_adjacent_waypoints(wp, adjacent_waypoints)
        
        area_waypoints += adjacent_waypoints

        self.world.tick()

        logger.debug(f'Compiled a list of {len(area_waypoints)} road waypoints.')
        logger.debug('Compiling a list of sidewalk points...')

        # Get the sidewalk points from area waypoints.
        sidewalk_points = []

        for wp in area_waypoints:
            self._get_sidewalk_points(wp, sidewalk_points)

            if wp.is_junction:
                waypoint = self.map.get_waypoint(wp.transform.location, lane_type=carla.LaneType.Sidewalk)
                
                if waypoint is not None:
                    sidewalk_points.append(waypoint)

                    self._get_sidewalk_points(waypoint, sidewalk_points)
        
        self.world.tick()

        logger.debug(f'Compiled a list of {len(sidewalk_points)} sidewalk points.')

        # Create a set of all road, lane, and section ID triplets. These
        # correspond to individual lane sections.
        road_lane_section_id_triplets = set([(wp.road_id, wp.section_id, wp.lane_id) for wp in area_waypoints])

        # Create a set of all sidewalk, lane, and section ID triplets. These
        # correspond to individual sidewalk sections.
        sidewalk_lane_section_id_triplets = set([(wp.road_id, wp.section_id, wp.lane_id) for wp in sidewalk_points])
        
        if self.map_name == 'Town07':
            for triplet in [(2, 0, 1), (2, 0, 8), (30, 0, 1), (30, 0, 8), (54, 0, 1), (54, 0, 8)]:
                sidewalk_lane_section_id_triplets.add(triplet)
        
        # Process the triplets to get dictionaries of unique road/lane ID
        # pairs each mapped to the list of their corresponding section IDs.
        road_lane_id_pairs = self._process_triplets(road_lane_section_id_triplets)
        sidewalk_lane_id_pairs = self._process_triplets(sidewalk_lane_section_id_triplets)

        logger.debug('Collecting comprehensive information about every lane section...')

        # Get comprehensive information about every lane section from the list
        # of road/lane ID pairs.
        self.road_sections = self._get_sections_from_id_pairs(road_lane_id_pairs)
        self.sidewalk_sections = self._get_sections_from_id_pairs(sidewalk_lane_id_pairs, roads=False)

        logger.debug(f'Collected information about {len(self.road_sections)} road sections.')
        logger.debug(f'Collected information about {len(self.sidewalk_sections)} sidewalk sections.')

        if self.map_name == 'Town06':
            all_sidewalks = [obj for obj in self.objects if '_Sidewalk_' in obj.name]

            self.sidewalk_meshes = []

            for sidewalk in all_sidewalks:
                bbox = sidewalk.bounding_box.get_local_vertices()

                bbox = carla_vector_to_numpy([bbox[0], bbox[2], bbox[6], bbox[4], bbox[0]])

                bbox[:, 1] *= -1.0

                self.sidewalk_meshes.append(bbox)
    
    def _get_adjacent_waypoints(self, wp: carla.Waypoint, adjacent_waypoints: List[carla.Waypoint]):
        '''
        Get all adjacent waypoints to the left and right of a given waypoint.

        Args:
            wp: subject waypoint.
            adjacent_waypoints: list to append adjacent waypoints to.
        '''
        for direction in [True, False]:
            awp = wp.get_left_lane() if direction else wp.get_right_lane()

            while awp:
                if awp.lane_type in self.good_lane_types:
                    adjacent_waypoints.append(awp)
                    
                    awp = awp.get_left_lane() if direction else awp.get_right_lane()
                elif awp.lane_type in self.conditional_lane_types:
                    if (awp.left_lane_marking.type in self.bad_lane_marking_types and
                        awp.right_lane_marking.type in self.bad_lane_marking_types):
                        awp = None
                    else:
                        adjacent_waypoints.append(awp)
                        
                        awp = awp.get_left_lane() if direction else awp.get_right_lane()
                else:
                    awp = None
    
    def _get_sidewalk_points(self, wp: carla.Waypoint, sidewalk_points: List[carla.Waypoint]):
        '''
        Get the sidewalk points to the left and right of a given waypoint.

        Args:
            wp: subject waypoint.
            sidewalk_points: list to append sidewalk points to.
        '''
        for direction in [True, False]:
            awp = wp.get_left_lane() if direction else wp.get_right_lane()

            while awp:
                if awp.lane_type is not carla.LaneType.Driving:
                    if awp.lane_type == carla.LaneType.Sidewalk:
                        sidewalk_points.append(awp)

                    awp = awp.get_left_lane() if direction else awp.get_right_lane()
                else:
                    awp = None
    
    def _process_triplets(self, triplet_list: List[tuple]) -> dict:
        '''
        Process a list of (road, section, lane) ID triplets to get a
        dictionary of unique road/lane ID pairs each mapped to the list of
        their corresponding section IDs.

        Args:
            triplet_list: list of (road, lane, section) ID triplets.
        
        Returns:
            id_pairs: dictionary of road/lane ID pairs mapped to section ID
                lists.
        '''
        id_pairs = {}

        for triplet in triplet_list:
            if (triplet[0], triplet[2]) not in id_pairs:
                id_pairs[(triplet[0], triplet[2])] = [triplet[1]]
            else:
                id_pairs[(triplet[0], triplet[2])].append(triplet[1])
        
        return id_pairs
    
    def _get_sections_from_id_pairs(self, id_pairs: dict, roads: bool = True) -> List[dict]:
        '''
        Get comprehensive information about every lane section from a
        dictionary of road/lane ID pairs each mapped to the list of their
        corresponding section IDs.

        Args:
            id_pairs: dictionary of road/lane ID pairs mapped to section ID
                lists.
            roads: boolean indicating if the sections are road sections.

        Returns:
            sections: list of dictionaries containing comprehensive information
                about each lane section.
        '''
        sections = []

        # For each lane section, calculate its border points, left and right
        # lane line points (if a road section), and its midline.
        for key, value in id_pairs.items():
            for section_id in value:
                section = {
                    'road_id': key[0],
                    'lane_id': key[1],
                    'section_id': section_id,
                    'left_border': [],
                    'right_border': [],
                    'midline': []
                }

                if roads:
                    section.update({'left_lane': [], 'right_lane': []})

                s = 0.0

                left_points = []
                right_points = []

                wp = self.map.get_waypoint_xodr(key[0], key[1], s)

                start_point_counter = 0
                midline_counter = 1

                if not roads:
                    if self.map_name == 'Town15':
                        if key == (156, -5) and section_id == 3:
                            s = 300.0
                        elif key == (117, 4) and section_id == 3:
                            s = 70.0
                        elif key == (203, -5) and section_id == 2:
                            s = 200.0

                while wp is None and start_point_counter < 2000:
                    s += self.config['waypoint_distance']
                    
                    wp = self.map.get_waypoint_xodr(key[0], key[1], s)
                    
                    start_point_counter += 1

                if wp is not None:
                    if wp.section_id == section_id:
                        section['midline'].append(wp.transform.location)

                    while wp is not None:
                        if wp.section_id == section_id:
                            next_midline_location = wp.transform.location

                            if midline_counter % 10 == 0:
                                section['midline'].append(next_midline_location)

                            wp_transform = wp.transform
                            
                            wp_transform.rotation.yaw += 90.0

                            # Get the left and right borders.
                            left_points.append(wp_transform.location - \
                                            0.5 * wp.lane_width * wp_transform.get_forward_vector())
                            right_points.append(wp_transform.location + \
                                                0.5 * wp.lane_width * wp_transform.get_forward_vector())

                            # Get the left and right borders of the lane lines.
                            if roads:
                                llm = wp.left_lane_marking

                                if llm.type not in self.bad_lane_marking_types:
                                    if llm.type in self.single_lane_marking_types:
                                        section['left_lane'].append(
                                            wp_transform.location - 
                                            0.5 * (wp.lane_width - llm.width) * wp_transform.get_forward_vector()
                                        )
                                    else:
                                        section['left_lane'].append(
                                            wp_transform.location - \
                                            0.5 * (wp.lane_width - 3 * llm.width) * wp_transform.get_forward_vector()
                                        )

                                rlm = wp.right_lane_marking

                                if rlm.type not in self.bad_lane_marking_types:
                                    if rlm.type in self.single_lane_marking_types:
                                        section['right_lane'].append(
                                            wp_transform.location + 
                                            0.5 * (wp.lane_width - rlm.width) * wp_transform.get_forward_vector()
                                        )
                                    else:
                                        section['right_lane'].append(
                                            wp_transform.location + \
                                            0.5 * (wp.lane_width - 3 * rlm.width) * wp_transform.get_forward_vector()
                                        )
                        
                            s += self.config['waypoint_distance']

                            wp = self.map.get_waypoint_xodr(key[0], key[1], s)

                            midline_counter += 1
                        else:
                            s += self.config['waypoint_distance']

                            wp = self.map.get_waypoint_xodr(key[0], key[1], s)

                    section['left_border'] = carla_vector_to_numpy(left_points)
                    section['right_border'] = carla_vector_to_numpy(right_points)

                    if roads:
                        section['left_lane'] = carla_vector_to_numpy(section['left_lane'])
                        section['right_lane'] = carla_vector_to_numpy(section['right_lane'])

                    section['midline'].append(next_midline_location)

                    section['left_border'][:, 1] *= -1.0
                    section['right_border'][:, 1] *= -1.0

                    if roads:
                        section['left_lane'][:, 1] *= -1.0
                        section['right_lane'][:, 1] *= -1.0

                    sections.append(section)
        
        return sections
    
    def get_area_crosswalks(self, crosswalks: List[carla.Location]):
        '''
        Get the crosswalks within the mapping area.

        Args:
            crosswalks: list of all crosswalk boundary locations.
        '''
        self.area_crosswalks = []

        logger.debug('Compiling a list of crosswalks...')

        # For Town01, Town02, Town12, and Town13, get the crosswalks from the
        # map data. For others, get the crosswalks from the list of
        # environment objects (the latter method is more accurate).
        if self.map_name in ['Town01', 'Town02','Town12', 'Town13']:
            for i in range(len(crosswalks)):
                for j in range(i + 1, len(crosswalks)):
                    if crosswalks[i].distance(crosswalks[j]) < 0.02 and \
                        crosswalks[i].distance(self.vehicle.get_location()) < self.config['mapping_area_radius']:
                            crosswalk = carla_vector_to_numpy(crosswalks[i:j + 1])

                            crosswalk[:, 1] *= -1.0

                            self.area_crosswalks.append(crosswalk)
        else:
            all_crosswalks = [obj for obj in self.objects if '_Crosswalk_' in obj.name]

            crosswalks = [cw for cw in all_crosswalks if not any(x in cw.name for x in BAD_CROSSWALKS)]

            for crosswalk in crosswalks:
                bbox = crosswalk.bounding_box.get_local_vertices()

                midpoint = (bbox[0] + bbox[7]) / 2

                if midpoint.distance(self.vehicle.get_location()) < self.config['mapping_area_radius']:
                    bbox = carla_vector_to_numpy([bbox[0], bbox[2], bbox[6], bbox[4], bbox[0]])

                    bbox[:, 1] *= -1.0

                    self.area_crosswalks.append(bbox)
        
        logger.debug(f'Compiled a list of {len(self.area_crosswalks)} crosswalks.')

    def trim_map_sections(self):
        '''
        Trim the list of road, sidewalk, and crosswalk sections and only leave
        those within the ego vehicle's perception range so ground truth
        calculations are more efficient.
        '''
        vehicle_location = carla_single_vector_to_numpy(self.vehicle.get_location()).reshape(1, -1)

        vehicle_location[:, 1] *= -1.0

        # Trim road sections.
        self.local_roads, self.local_road_midlines, self.local_road_lines = self._process_sections(self.road_sections)

        # Trim sidewalk sections.
        self.local_sidewalks = self._process_sections(self.sidewalk_sections, roads=False)

        # Trim crosswalk sections.
        self.local_crosswalks = [crosswalk.copy() for crosswalk in self.area_crosswalks if \
                                 np.min(cdist(crosswalk, vehicle_location)) < \
                                    self.config['nearby_mapping_area_radius']]

        # For Town06, also trim sidewalk meshes.
        if self.map_name == 'Town06':
            self.local_sidewalk_meshes = [sidewalk.copy() for sidewalk in self.sidewalk_meshes if \
                                          np.min(cdist(sidewalk, vehicle_location)) < \
                                            self.config['nearby_mapping_area_radius']]
    
    def _process_sections(self, sections: List[dict], roads: bool = True) -> List[np.ndarray]:
        '''
        Process a list of lane sections and only keep those within a
        certain distance of the ego vehicle.

        Args:
            sections: list of lane sections.
            roads: boolean indicating if the sections are road sections.
        '''
        chunk_size = 40

        vehicle_location = self.vehicle.get_location()

        local_sections = []

        if roads:
            local_midlines = []
            local_lines = []
        
        for section in sections:
            if any(vehicle_location.distance(location) < self.config['nearby_mapping_area_radius'] \
                   for location in section['midline']):
                left_border = section['left_border']
                right_border = section['right_border']

                # Split long sections into smaller chunks to avoid
                # unnecessary processing.
                if left_border.shape[0] < chunk_size:
                    local_sections.append(np.vstack((left_border, right_border[::-1])))
                else:
                    for i in range(0, left_border.shape[0], chunk_size):
                        j = min(i + chunk_size, left_border.shape[0])

                        local_sections.append(np.vstack((left_border[i:j], right_border[i:j][::-1])))

                if roads:
                    if len(section['left_lane']) > 0:
                        local_lines.append(section['left_lane'])

                    if len(section['right_lane']) > 0:
                        local_lines.append(section['right_lane'])

                    for location in section['midline']:
                        if vehicle_location.distance(location) < self.config['nearby_mapping_area_radius']:
                            local_midlines.append(location)
        
        if roads:
            local_midlines = carla_vector_to_numpy(local_midlines)

            return local_sections, local_midlines, local_lines
        else:
            return local_sections

    def _process_level_sections(self, sections: List[np.ndarray]) -> List[np.ndarray]:
        '''
        Process the list of sections and only keep those within a
        certain elevation of the ego vehicle.

        Args:
            sections: list of sections.
        
        Returns:
            level_sections: list of the desired sections.
        '''
        vehicle_location = self.vehicle.get_location()

        level_sections = []

        for section in sections:
            mask = np.abs(section[:, 2] - vehicle_location.z) < 4.8

            level_sections.append(section[mask])

        return level_sections

    def get_bev_gt(self, elevation_difference: bool = False) -> np.ndarray:
        '''
        Get the BEV ground truth using the top and bottom semantic cameras,
        map sections, and 3D object bounding boxes.

        Args:
            elevation_difference: boolean indicating areas of different
                elevation are present in the scene.
        
        Returns:
            bev_gt: BEV ground truth.
        '''
        vehicle_transform = self.vehicle.get_transform()

        mask = {
            'road': None,
            'road_line': None,
            'sidewalk': None,
            'crosswalk': None,
            'car': None,
            'truck': None,
            'bus': None,
            'motorcycle': None,
            'bicycle': None,
            'rider': None,
            'pedestrian': None
        }

        # If significant elevation difference is present in the scene, process
        # map sections and only keep those that are within a certain elevation
        # of the ego vehicle.
        level_roads = self._process_level_sections(self.local_roads) \
            if elevation_difference else self.local_roads
        level_road_lines = self._process_level_sections(self.local_road_lines) \
            if elevation_difference else self.local_road_lines
        level_sidewalks = self._process_level_sections(self.local_sidewalks) \
            if elevation_difference else self.local_sidewalks
        level_crosswalks = [cw for cw in self.local_crosswalks if abs(cw[0, 2] - vehicle_transform.location.z) < 4.8] \
            if elevation_difference else self.local_crosswalks

        # Get the road mask from road sections.
        wp_road_mask = get_multi_polygon_mask(
            level_roads,
            vehicle_transform,
            self.config['bev_dim'],
            self.config['bev_res']
        )

        # Get the road line mask from road lines.
        mask['road_line'] = get_multi_line_mask(
            level_road_lines,
            vehicle_transform,
            self.config['bev_dim'],
            self.config['bev_res']
        )
        
        # Get the sidewalk mask from sidewalk sections.
        wp_sidewalk_mask = get_multi_polygon_mask(
            level_sidewalks,
            vehicle_transform,
            self.config['bev_dim'],
            self.config['bev_res']
        )

        # For Town06, get the sidewalk mask from sidewalk meshes.
        if self.map_name == 'Town06':
            mesh_sidewalk_mask = get_multi_polygon_mask(
                self.local_sidewalk_meshes,
                vehicle_transform,
                self.config['bev_dim'],
                self.config['bev_res']
            )

        # Get the crosswalk mask from crosswalk locations.
        crosswalk_mask = get_multi_polygon_mask(
            level_crosswalks,
            vehicle_transform,
            self.config['bev_dim'],
            self.config['bev_res']
        )

        if elevation_difference:
            mask['road'] = binary_closing(wp_road_mask)
            mask['sidewalk'] = binary_closing(wp_sidewalk_mask)
            mask['crosswalk'] = binary_closing(np.logical_and(crosswalk_mask, mask['road']))

            bbox_list = {
                'car': [],
                'truck': [],
                'bus': [],
                'motorcycle': [],
                'bicycle': [],
                'rider': [],
                'pedestrian': []
            }

            actors = self.get_bounding_boxes()

            for actor in actors:
                if any(x in actor['semantic_tags'] for x in [12, 13, 14, 15, 16, 18, 19]):
                    if np.abs(actor['bounding_box'][::2, 2] - vehicle_transform.location.z).max() < 4.8:
                        bbox = actor['bounding_box']

                        bbox = np.array([bbox[0], bbox[2], bbox[6], bbox[4], bbox[0]])

                        if 12 in actor['semantic_tags']:
                            bbox_list['pedestrian'].append(bbox)
                        if 13 in actor['semantic_tags']:
                            bbox_list['rider'].append(bbox)
                        if 14 in actor['semantic_tags']:
                            bbox_list['car'].append(bbox)
                        if 15 in actor['semantic_tags']:
                            bbox_list['truck'].append(bbox)
                        if 16 in actor['semantic_tags']:
                            bbox_list['bus'].append(bbox)
                        if 18 in actor['semantic_tags']:
                            bbox_list['motorcycle'].append(bbox)
                        if 19 in actor['semantic_tags']:
                            bbox_list['bicycle'].append(bbox)
            
            for key in bbox_list.keys():
                if len(bbox_list[key]) > 0:
                    mask[key] = get_multi_polygon_mask(
                        bbox_list[key],
                        vehicle_transform,
                        self.config['bev_dim'],
                        self.config['bev_res']
                    )
                else:
                    mask[key] = np.zeros((self.config['bev_dim'], self.config['bev_dim']), dtype=bool)
        else:
            # Get the images from the top and bottom semantic cameras. Use the
            # top image along with the masks from map sections to create masks
            # for the road, sidewalks (if specified), and crosswalks, and use
            # both images to create masks for cars, trucks, buses,
            # motorcycles, bicycles, riders, and pedestrians.
            top_bev_image = self.sensor_manager.sensor_list['semantic_bev_camera'][0].get_save_queue().get(True, 10.0)
            bottom_bev_image = np.flip(
                self.sensor_manager.sensor_list['semantic_bev_camera'][1].get_save_queue().get(True, 10.0),
                axis=0
            )

            bev_road_mask = np.logical_or(top_bev_image[:, :, 2] == 128, top_bev_image[:, :, 2] == 157)

            mask['road'] = binary_closing(np.logical_or(wp_road_mask, bev_road_mask))
            
            if self.config['use_bev_for_sidewalks']:
                mask['sidewalk'] = binary_closing(np.logical_or(top_bev_image[:, :, 0] == 232, wp_sidewalk_mask))
            elif self.map_name == 'Town06':
                mask['sidewalk'] = binary_closing(np.logical_or(
                    wp_sidewalk_mask,
                    np.logical_and(
                        mesh_sidewalk_mask,
                        np.logical_or(top_bev_image[:, :, 0] == 232, bottom_bev_image[:, :, 0] == 232)
                    )
                ))
            else:
                mask['sidewalk'] = binary_closing(wp_sidewalk_mask)

            if self.map_name in ['Town12', 'Town13']:
                bev_crosswalk_mask = binary_opening(
                    np.logical_or(top_bev_image[:, :, 2] == 157, crosswalk_mask),
                    footprint=np.ones((3, 3))
                )
            else:
                bev_crosswalk_mask = crosswalk_mask

            mask['crosswalk'] = binary_closing(np.logical_and(bev_crosswalk_mask, mask['road']))

            mask['car'] = np.logical_or(bottom_bev_image[:, :, 0] == 142, top_bev_image[:, :, 0] == 142)
            mask['truck'] = np.logical_or(
                np.logical_and(bottom_bev_image[:, :, 0] == 70, bottom_bev_image[:, :, 1] == 0),
                np.logical_and(top_bev_image[:, :, 0] == 70, top_bev_image[:, :, 1] == 0)
            )
            mask['bus'] = np.logical_or(
                np.logical_and(bottom_bev_image[:, :, 0] == 100, bottom_bev_image[:, :, 1] == 60),
                np.logical_and(top_bev_image[:, :, 0] == 100, top_bev_image[:, :, 1] == 60)
            )
            mask['motorcycle'] = np.logical_or(bottom_bev_image[:, :, 0] == 230, top_bev_image[:, :, 0] == 230)
            mask['bicycle'] = np.logical_or(bottom_bev_image[:, :, 0] == 32, top_bev_image[:, :, 0] == 32)
            mask['rider'] = np.logical_or(bottom_bev_image[:, :, 2] == 255, top_bev_image[:, :, 2] == 255)
            mask['pedestrian'] = np.logical_or(bottom_bev_image[:, :, 1] == 20, top_bev_image[:, :, 1] == 20)
        
        # Concatenate individual masks to get the ground truth.
        bev_gt = np.array([mask[key] for key in mask.keys()])

        return bev_gt

    # TODO: Think about semi-reckless ego.
    
    def get_bounding_boxes(self):
        '''
        Get the bounding box of actors (including traffic elements) in the
        scene that are within a certain radius of the ego vehicle.
        '''
        self.actors = []

        actor_list = self.world.get_actors()

        vehicle_location = self.vehicle.get_location()

        for actor in actor_list:
            actor_properties = {}
            actor_location = actor.get_location()

            if vehicle_location.distance(actor_location) < self.config['bbox_collection_radius'] \
                and all(x not in actor.type_id for x in ['spectator', 'sensor', 'controller']) \
                    and any(x in actor.semantic_tags for x in [12, 13, 14, 15, 16, 18, 19]):
                actor_properties['id'] = actor.id
                actor_properties['type'] = str(actor.type_id)
                actor_properties['is_alive'] = actor.is_alive
                actor_properties['is_active'] = actor.is_active
                actor_properties['is_dormant'] = actor.is_dormant
                actor_properties['parent'] = actor.parent.id if actor.parent is not None else None
                actor_properties['attributes'] = actor.attributes
                actor_properties['semantic_tags'] = actor.semantic_tags

                bounding_box = actor.bounding_box
                
                if 'use_wheelchair' in actor_properties['attributes'] and actor_properties['attributes']['use_wheelchair'] == 'true':
                    bounding_box.extent = carla.Vector3D(0.64, 0.48, 0.8)

                    bounding_box.location.x += (0.6 - actor.bounding_box.extent.x)
                    bounding_box.location.z += (0.8 - actor.bounding_box.extent.z)
                elif actor_properties['type'] in ['walker.pedestrian.0050', 'walker.pedestrian.0051']:
                    bounding_box.extent *= 0.65

                    bounding_box.location.z += (bounding_box.extent.z - actor.bounding_box.extent.z)

                actor_properties['bounding_box'] = carla_vector_to_numpy(
                    bounding_box.get_world_vertices(actor.get_transform())
                )
                
                actor_properties['linear_velocity'] = carla_single_vector_to_numpy(actor.get_velocity())
                actor_properties['angular_velocity'] = carla_single_vector_to_numpy(actor.get_angular_velocity())

                actor_properties['bounding_box'][:, 1] *= -1.0
                actor_properties['linear_velocity'][1] *= -1.0
                actor_properties['angular_velocity'][1:] *= -1.0

                self.actors.append(actor_properties)

            # Get traffic lights.
            if self.config['collect_traffic_light_bbox']:
                if isinstance(actor, carla.TrafficLight):
                    if vehicle_location.distance(actor_location) < self.config['bbox_collection_radius']:
                        bounding_boxes = actor.get_light_boxes()

                        for bounding_box in bounding_boxes:
                            if bounding_box.extent.z > 0.3:
                                actor_properties = {}

                                actor_properties['id'] = actor.id
                                actor_properties['type'] = str(actor.type_id)
                                actor_properties['is_alive'] = actor.is_alive
                                actor_properties['is_active'] = actor.is_active
                                actor_properties['is_dormant'] = actor.is_dormant
                                actor_properties['parent'] = actor.parent.id if actor.parent is not None else None
                                actor_properties['attributes'] = actor.attributes
                                actor_properties['semantic_tags'] = [7]

                                if self.map_name in ['Town12', 'Town13']:
                                    tile_bounding_box = carla_vector_to_numpy(bounding_box.get_local_vertices())

                                    x_difference = np.round((actor_location.x - bounding_box.location.x) / 1000.0) \
                                        * 1000.0
                                    y_difference = np.round((actor_location.y - bounding_box.location.y) / 1000.0) \
                                        * 1000.0

                                    actor_properties['bounding_box'] = tile_bounding_box + np.array([
                                        x_difference, y_difference, 0.0
                                    ])
                                else:
                                    actor_properties['bounding_box'] = carla_vector_to_numpy(
                                        bounding_box.get_local_vertices()
                                    )

                                actor_properties['linear_velocity'] = np.zeros(3)
                                actor_properties['angular_velocity'] = np.zeros(3)

                                actor_properties['bounding_box'][:, 1] *= -1.0

                                actor_properties['green_time'] = actor.get_green_time()
                                actor_properties['yellow_time'] = actor.get_yellow_time()
                                actor_properties['red_time'] = actor.get_red_time()
                                
                                actor_properties['state'] = str(actor.get_state())

                                actor_properties['opendrive_id'] = actor.get_opendrive_id()
                                actor_properties['pole_index'] = actor.get_pole_index()

                                self.actors.append(actor_properties)
        
        # Get the list of objects (props) in the scene, i.e. parked cars,
        # trucks, etc. that are within a certain radius of the ego vehicle.
        if self.config['collect_traffic_sign_bbox']:
            traffic_sign_list = self.world.get_environment_objects(carla.CityObjectLabel.TrafficSigns)
        
        car_list = self.world.get_environment_objects(carla.CityObjectLabel.Car)
        truck_list = self.world.get_environment_objects(carla.CityObjectLabel.Truck)
        bus_list = self.world.get_environment_objects(carla.CityObjectLabel.Bus)
        motorcycle_list = self.world.get_environment_objects(carla.CityObjectLabel.Motorcycle)
        bicycle_list = self.world.get_environment_objects(carla.CityObjectLabel.Bicycle)

        if self.config['collect_traffic_sign_bbox']:
            object_list = traffic_sign_list + car_list + truck_list + bus_list + motorcycle_list + bicycle_list
        else:
            object_list = car_list + truck_list + bus_list + motorcycle_list + bicycle_list

        for obj in object_list:
            object_properties = {}
            object_location = obj.transform.location if self.map_name not in ['Town12', 'Town13'] \
                else obj.bounding_box.location

            if vehicle_location.distance(object_location) < self.config['bbox_collection_radius']:
                object_properties['id'] = obj.id
                object_properties['type'] = str(obj.type)
                object_properties['is_alive'] = False
                object_properties['is_active'] = False
                object_properties['is_dormant'] = False
                object_properties['parent'] = None
                object_properties['attributes'] = {}
                object_properties['bounding_box'] = carla_vector_to_numpy(obj.bounding_box.get_local_vertices())
                object_properties['linear_velocity'] = np.zeros(3)
                object_properties['angular_velocity'] = np.zeros(3)

                object_properties['bounding_box'][:, 1] *= -1.0

                if obj.type == carla.CityObjectLabel.TrafficSigns:
                    object_properties['semantic_tags'] = [8]
                    object_properties['sign_type'] = ''

                    for sign in TRAFFIC_SIGN.keys():
                        if sign in obj.name:
                            object_properties['sign_type'] = TRAFFIC_SIGN[sign]

                    if self.map_name not in ['Town12', 'Town13', 'Town15'] and \
                        'speed_limit' in object_properties['sign_type']:
                        object_properties['sign_type'] = 'speed_limit'

                elif obj.type == carla.CityObjectLabel.Car:
                    object_properties['semantic_tags'] = [14]
                elif obj.type == carla.CityObjectLabel.Truck:
                    object_properties['semantic_tags'] = [15]
                elif obj.type == carla.CityObjectLabel.Bus:
                    object_properties['semantic_tags'] = [16]
                elif obj.type == carla.CityObjectLabel.Motorcycle:
                    object_properties['semantic_tags'] = [18]
                elif obj.type == carla.CityObjectLabel.Bicycle:
                    object_properties['semantic_tags'] = [19]
                else:
                    object_properties['semantic_tags'] = []

                self.actors.append(object_properties)
        
        return self.actors

    def get_hd_map_info(self):
        '''
        Get HD map information from the waypoint at the vehicle's current location.
        '''
        hd_map_info = {}

        # Get the waypoint at the vehicle's current location.
        wp = self.map.get_waypoint(self.vehicle.get_location())

        hd_map_info['id'] = wp.id
        hd_map_info['s'] = wp.s
        hd_map_info['road_id'] = wp.road_id
        hd_map_info['section_id'] = wp.section_id
        hd_map_info['lane_id'] = wp.lane_id
        hd_map_info['lane_type'] = str(wp.lane_type)
        hd_map_info['lane_width'] = wp.lane_width
        hd_map_info['lane_change'] = str(wp.lane_change)

        hd_map_info['is_junction'] = wp.is_junction
        hd_map_info['junction_id'] = wp.junction_id if wp.is_junction else None
        hd_map_info['is_intersection'] = wp.is_intersection

        hd_map_info['left_lane_marking'] = {
            'type': str(wp.left_lane_marking.type),
            'width': wp.left_lane_marking.width,
            'color': str(wp.left_lane_marking.color),
            'lane_change': str(wp.left_lane_marking.lane_change)
        }

        hd_map_info['right_lane_marking'] = {
            'type': str(wp.right_lane_marking.type),
            'width': wp.right_lane_marking.width,
            'color': str(wp.right_lane_marking.color),
            'lane_change': str(wp.right_lane_marking.lane_change)
        }

        hd_map_info['transform'] = {
            'x': wp.transform.location.x,
            'y': -wp.transform.location.y,
            'z': wp.transform.location.z,
            'roll': wp.transform.rotation.roll,
            'pitch': -wp.transform.rotation.pitch,
            'yaw': -wp.transform.rotation.yaw
        }

        left_lane_wp = wp.get_left_lane()
        right_lane_wp = wp.get_right_lane()

        hd_map_info['left_lane'] = {}
        hd_map_info['right_lane'] = {}

        if left_lane_wp is not None:
            hd_map_info['left_lane']['id'] = left_lane_wp.id
            hd_map_info['left_lane']['s'] = left_lane_wp.s
            hd_map_info['left_lane']['road_id'] = left_lane_wp.road_id
            hd_map_info['left_lane']['section_id'] = left_lane_wp.section_id
            hd_map_info['left_lane']['lane_id'] = left_lane_wp.lane_id
            hd_map_info['left_lane']['lane_type'] = str(left_lane_wp.lane_type)
            hd_map_info['left_lane']['lane_width'] = left_lane_wp.lane_width
            hd_map_info['left_lane']['lane_change'] = str(left_lane_wp.lane_change)

        if right_lane_wp is not None:
            hd_map_info['right_lane']['id'] = right_lane_wp.id
            hd_map_info['right_lane']['s'] = right_lane_wp.s
            hd_map_info['right_lane']['road_id'] = right_lane_wp.road_id
            hd_map_info['right_lane']['section_id'] = right_lane_wp.section_id
            hd_map_info['right_lane']['lane_id'] = right_lane_wp.lane_id
            hd_map_info['right_lane']['lane_type'] = str(right_lane_wp.lane_type)
            hd_map_info['right_lane']['lane_width'] = right_lane_wp.lane_width
            hd_map_info['right_lane']['lane_change'] = str(right_lane_wp.lane_change)
        
        return hd_map_info
    
    def _prepare_canvas(self):
        background = (255, 255, 255)
    
        canvas = np.zeros((self.config['bev_dim'], self.config['bev_dim'], 3), dtype=np.uint8)
        canvas[:] = background

        if self.config['use_cityscapes_palette']:
            PALETTE = CITYSCAPE_PALETTE
        else:
            PALETTE = MAP_PALETTE
        
        for k, name in enumerate(PALETTE):
            canvas[self.bev_gt[k], :] = PALETTE[name]

        canvas = cv2.cvtColor(canvas, cv2.COLOR_RGB2BGR)

        return canvas
    
    def get_ground_truth(self):
        # If nearby roads do not have an elevation difference of more than
        # 6.4 meters, get the ground truth using the top and bottom
        # semantic cameras and road waypoints. Otherwise (i.e. when near
        # an overpass/underpass), get the ground truth using bounding
        # boxes and road waypoints.
        if self.map_name not in ['Town04', 'Town05', 'Town12', 'Town13']:
            self.bev_gt = self.get_bev_gt()
            self.warning_flag = False
        elif np.max(self.local_road_midlines[:, 2]) - np.min(self.local_road_midlines[:, 2]) < 6.4:
            self.bev_gt = self.get_bev_gt()
            self.warning_flag = False
        else:
            mid = (np.max(self.local_road_midlines[:, 2]) + np.min(self.local_road_midlines[:, 2])) / 2.0

            highs = self.local_road_midlines[self.local_road_midlines[:, 2] > (mid + 3.2)]
            lows = self.local_road_midlines[self.local_road_midlines[:, 2] < (mid - 3.2)]

            dists = cdist(highs[:, :2], lows[:, :2])

            if np.min(dists) > 48.0:
                self.bev_gt = self.get_bev_gt()
                self.warning_flag = False
            else:
                self.bev_gt = self.get_bev_gt(elevation_difference=True)

                if self.warning_flag is False:
                    logger.warning('Using alternative ground truth generation method due to elevation difference '
                                    'in the road.')

                    self.warning_flag = True
        
        self.canvas = self._prepare_canvas()
    
    def render(self):
        '''
        Render the BEV ground truth.
        '''
        cv2.imshow('Ground Truth', self.canvas)
        cv2.waitKey(1)
    
    def save(self, path, scene, frame):
        with open(
            f'{path}/simbev/ground-truth/seg/SimBEV-scene-{scene:04d}-frame-{frame:04d}-GT_SEG.npz', 'wb') as f:
            np.savez_compressed(f, data=self.bev_gt)

        cv2.imwrite(
            f'{path}/simbev/ground-truth/seg_viz/SimBEV-scene-{scene:04d}-frame-{frame:04d}-GT_SEG_VIZ.jpg',
            self.canvas
        )
        
        self.get_bounding_boxes()

        with open(f'{path}/simbev/ground-truth/det/SimBEV-scene-{scene:04d}-frame-{frame:04d}-GT_DET.bin', 'wb') as f:
            np.save(f, np.array(self.actors), allow_pickle=True)

        hd_map_info = self.get_hd_map_info()

        with open(
            f'{path}/simbev/ground-truth/hd_map/SimBEV-scene-{scene:04d}-frame-{frame:04d}-HD_MAP.json',
            'w'
        ) as f:
            json.dump(hd_map_info, f, indent=4)